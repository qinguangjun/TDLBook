<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 9 章 实现与实验 | 拓扑深度学习：超越图数据</title>
  <meta name="description" content="一本关于拓扑深度学习的书。" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="第 9 章 实现与实验 | 拓扑深度学习：超越图数据" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="一本关于拓扑深度学习的书。" />
  <meta name="github-repo" content="pyt-team/tdlbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 9 章 实现与实验 | 拓扑深度学习：超越图数据" />
  
  <meta name="twitter:description" content="一本关于拓扑深度学习的书。" />
  

<meta name="author" content="Mustafa Hajij, Theodore Papamarkou, Ghada Zamzmi, Karthikeyan Natesan Ramamurthy, Tolga Birdal, Michael T. Schaub" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="hasse-graph-interpretation-of-ccnns-1.html"/>
<link rel="next" href="related-work.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/glossarybox.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">拓扑深度学习</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>贡献者</a></li>
<li class="chapter" data-level="" data-path="翻译说明.html"><a href="翻译说明.html"><i class="fa fa-check"></i>翻译说明</a></li>
<li class="chapter" data-level="" data-path="序言.html"><a href="序言.html"><i class="fa fa-check"></i>序言</a>
<ul>
<li class="chapter" data-level="" data-path="序言.html"><a href="序言.html#编译"><i class="fa fa-check"></i>编译</a></li>
<li class="chapter" data-level="" data-path="序言.html"><a href="序言.html#致谢"><i class="fa fa-check"></i>致谢</a></li>
</ul></li>
<li class="part"><span><b>第一部分：基础知识</b></span></li>
<li class="chapter" data-level="1" data-path="引言.html"><a href="引言.html"><i class="fa fa-check"></i><b>1</b> 引言</a></li>
<li class="chapter" data-level="2" data-path="motivation.html"><a href="motivation.html"><i class="fa fa-check"></i><b>2</b> 研究动机</a>
<ul>
<li class="chapter" data-level="2.1" data-path="motivation.html"><a href="motivation.html#从拓扑空间数据中建模和学习"><i class="fa fa-check"></i><b>2.1</b> 从拓扑空间数据中建模和学习</a></li>
<li class="chapter" data-level="2.2" data-path="motivation.html"><a href="motivation.html#the-utility-of-topology"><i class="fa fa-check"></i><b>2.2</b> 拓扑的有用性</a></li>
<li class="chapter" data-level="2.3" data-path="motivation.html"><a href="motivation.html#深度学习和结构化计算的统一视角"><i class="fa fa-check"></i><b>2.3</b> 深度学习和结构化计算的统一视角</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="preliminaries.html"><a href="preliminaries.html"><i class="fa fa-check"></i><b>3</b> 预备知识</a>
<ul>
<li class="chapter" data-level="3.1" data-path="preliminaries.html"><a href="preliminaries.html#邻域函数和拓扑空间"><i class="fa fa-check"></i><b>3.1</b> 邻域函数和拓扑空间</a></li>
<li class="chapter" data-level="3.2" data-path="preliminaries.html"><a href="preliminaries.html#bridging-the-gap-among-higher-order-networks"><i class="fa fa-check"></i><b>3.2</b> 填补与高阶网络间的代沟</a></li>
<li class="chapter" data-level="3.3" data-path="preliminaries.html"><a href="preliminaries.html#hierarchical-structure-and-set-type-relations"><i class="fa fa-check"></i><b>3.3</b> 层次化结构与集合型关系</a></li>
</ul></li>
<li class="part"><span><b>第二部分:组合复形</b></span></li>
<li class="chapter" data-level="4" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html"><i class="fa fa-check"></i><b>4</b> 组合复形</a>
<ul>
<li class="chapter" data-level="4.1" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html#cc-definition"><i class="fa fa-check"></i><b>4.1</b> 组合复形定义</a></li>
<li class="chapter" data-level="4.2" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html#cc-homomorphisms-and-sub-ccs"><i class="fa fa-check"></i><b>4.2</b> CC同态和子CCs</a></li>
<li class="chapter" data-level="4.3" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html#motivation-for-ccs"><i class="fa fa-check"></i><b>4.3</b> 引入CCs的动机</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html#pooling-operations-on-ccs"><i class="fa fa-check"></i><b>4.3.1</b> CCs上的池化操作</a></li>
<li class="chapter" data-level="4.3.2" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html#structural-advantages-of-ccs"><i class="fa fa-check"></i><b>4.3.2</b> CCs的结构化优势</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html#neighbourhood-functions-on-ccs"><i class="fa fa-check"></i><b>4.4</b> CCs上的邻域函数</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html#incidence-in-a-cc"><i class="fa fa-check"></i><b>4.4.1</b> CC中的关联关系（Incidence）</a></li>
<li class="chapter" data-level="4.4.2" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html#cc内的邻接关系adjacency"><i class="fa fa-check"></i><b>4.4.2</b> CC内的邻接关系（Adjacency）</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="combinatorial-complexes.html"><a href="combinatorial-complexes.html#data-on-ccs"><i class="fa fa-check"></i><b>4.5</b> CCs上的数据</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="combinatorial-complex-neural-networks.html"><a href="combinatorial-complex-neural-networks.html"><i class="fa fa-check"></i><b>5</b> 组合复形神经网络（Combinatorial complex neural networks）</a>
<ul>
<li class="chapter" data-level="5.1" data-path="combinatorial-complex-neural-networks.html"><a href="combinatorial-complex-neural-networks.html#building-ccnns-tensor-diagrams"><i class="fa fa-check"></i><b>5.1</b> 构建 CCNN：张量图</a></li>
<li class="chapter" data-level="5.2" data-path="combinatorial-complex-neural-networks.html"><a href="combinatorial-complex-neural-networks.html#push-forward-operator-and-merge-node"><i class="fa fa-check"></i><b>5.2</b> 前推操作（Push-forward operator）和聚合节点</a></li>
<li class="chapter" data-level="5.3" data-path="combinatorial-complex-neural-networks.html"><a href="combinatorial-complex-neural-networks.html#the-main-three-tensor-operations"><i class="fa fa-check"></i><b>5.3</b> 三种主要的张量操作</a></li>
<li class="chapter" data-level="5.4" data-path="combinatorial-complex-neural-networks.html"><a href="combinatorial-complex-neural-networks.html#definition-of-combinatorial-complex-convolutional-networks"><i class="fa fa-check"></i><b>5.4</b> 组合复形卷积网络的定义（combinatorial complex convolutional networks）</a></li>
<li class="chapter" data-level="5.5" data-path="combinatorial-complex-neural-networks.html"><a href="combinatorial-complex-neural-networks.html#combinatorial-complex-attention-neural-networks"><i class="fa fa-check"></i><b>5.5</b> 组合复形注意力神经网络</a></li>
</ul></li>
<li class="part"><span><b>第三部分：高阶消息传递（Higher-order message passing）</b></span></li>
<li class="chapter" data-level="6" data-path="message-passing.html"><a href="message-passing.html"><i class="fa fa-check"></i><b>6</b> 消息传递</a>
<ul>
<li class="chapter" data-level="6.1" data-path="message-passing.html"><a href="message-passing.html#definition-of-higher-order-message-passing"><i class="fa fa-check"></i><b>6.1</b> 高阶消息传递的定义</a></li>
<li class="chapter" data-level="6.2" data-path="message-passing.html"><a href="message-passing.html#higher-order-message-passing-neural-networks-are-ccnns"><i class="fa fa-check"></i><b>6.2</b> 高阶消息传递神经网络就是CCNNs</a></li>
<li class="chapter" data-level="6.3" data-path="message-passing.html"><a href="message-passing.html#merge-nodes-and-higher-order-message-passing-a-qualitative-comparison"><i class="fa fa-check"></i><b>6.3</b> 聚合节点和高阶消息传递：量化比较</a></li>
<li class="chapter" data-level="6.4" data-path="message-passing.html"><a href="message-passing.html#attention-higher-order-message-passing-and-ccanns"><i class="fa fa-check"></i><b>6.4</b> 注意力高阶消息传递和CCANNs</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="push-forward-pooling-and-unpooling.html"><a href="push-forward-pooling-and-unpooling.html"><i class="fa fa-check"></i><b>7</b> 前推、池化和反池化</a>
<ul>
<li class="chapter" data-level="7.1" data-path="push-forward-pooling-and-unpooling.html"><a href="push-forward-pooling-and-unpooling.html#cc-pooling-and-unpooling"><i class="fa fa-check"></i><b>7.1</b> CC池化和反池化</a></li>
<li class="chapter" data-level="7.2" data-path="push-forward-pooling-and-unpooling.html"><a href="push-forward-pooling-and-unpooling.html#formulating-common-pooling-operations-as-cc-pooling"><i class="fa fa-check"></i><b>7.2</b> 将常见的池化操作表述为 CC-pooling</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="push-forward-pooling-and-unpooling.html"><a href="push-forward-pooling-and-unpooling.html#graph-pooling-as-cc-pooling"><i class="fa fa-check"></i><b>7.2.1</b> 用CC-pooling表示图池化操作</a></li>
<li class="chapter" data-level="7.2.2" data-path="push-forward-pooling-and-unpooling.html"><a href="push-forward-pooling-and-unpooling.html#image-pooling-as-cc-pooling"><i class="fa fa-check"></i><b>7.2.2</b> 图像池化作为CC-pooing</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="push-forward-pooling-and-unpooling.html"><a href="push-forward-pooling-and-unpooling.html#pooling-and-unpooling-ccnns"><i class="fa fa-check"></i><b>7.3</b> 池化与反池化CCNNs</a></li>
<li class="chapter" data-level="7.4" data-path="push-forward-pooling-and-unpooling.html"><a href="push-forward-pooling-and-unpooling.html#mapper-and-the-cc-pooling-operation"><i class="fa fa-check"></i><b>7.4</b> 映射器和CC池化操作</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html"><i class="fa fa-check"></i><b>8</b> CCNNs的Hasse图解释</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#hasse-graph-interpretation-of-ccnns-2"><i class="fa fa-check"></i><b>8.1</b> CCNNs的Hasse图解释</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#ccs-as-hasse-graphs"><i class="fa fa-check"></i><b>8.1.1</b> CCs作为Hasse图</a></li>
<li class="chapter" data-level="8.1.2" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#augmented-hasse-graphs"><i class="fa fa-check"></i><b>8.1.2</b> 增强的Hasse图</a></li>
<li class="chapter" data-level="8.1.3" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#reducibility-of-ccnns-to-graph-basedmodels"><i class="fa fa-check"></i><b>8.1.3</b> CCNN对图模型的归约能力</a></li>
<li class="chapter" data-level="8.1.4" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#augmented-hasse-graphs-and-cc-pooling"><i class="fa fa-check"></i><b>8.1.4</b> 增强Hasse图和CC-pooling</a></li>
<li class="chapter" data-level="8.1.5" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#augmented-hasse-diagrams-message-passing-and-mergenodes"><i class="fa fa-check"></i><b>8.1.5</b> 增强Hasse图消息传递和聚合节点</a></li>
<li class="chapter" data-level="8.1.6" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#higher-order-representation-learning"><i class="fa fa-check"></i><b>8.1.6</b> 高阶表征学习</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#on-the-equivariance-of-ccnns"><i class="fa fa-check"></i><b>8.2</b> CCNNs的等变性</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#permutation-equivariance-of-ccnns"><i class="fa fa-check"></i><b>8.2.1</b> CCNNs的置换等变</a></li>
<li class="chapter" data-level="8.2.2" data-path="hasse-graph-interpretation-of-ccnns-1.html"><a href="hasse-graph-interpretation-of-ccnns-1.html#orientation-equivariance-of-ccnns"><i class="fa fa-check"></i><b>8.2.2</b> CCNNs的方向等变</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>第四部分：应用，文献和结论</b></span></li>
<li class="chapter" data-level="9" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html"><i class="fa fa-check"></i><b>9</b> 实现与实验</a>
<ul>
<li class="chapter" data-level="9.1" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#software-toponetx-topoembedx-and-topomodelx"><i class="fa fa-check"></i><b>9.1</b> 软件：TopoNetX, TopoEmbedX, and TopoModelX</a></li>
<li class="chapter" data-level="9.2" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#datasets"><i class="fa fa-check"></i><b>9.2</b> 数据集</a></li>
<li class="chapter" data-level="9.3" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#shape-analysis-mesh-segmentation-and-classification"><i class="fa fa-check"></i><b>9.3</b> 形状分析：网格分割与分类</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#mesh-segmentation"><i class="fa fa-check"></i><b>9.3.1</b> 网格分割</a></li>
<li class="chapter" data-level="9.3.2" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#mesh-and-point-cloud-classification"><i class="fa fa-check"></i><b>9.3.2</b> 网格和点云分类</a></li>
<li class="chapter" data-level="9.3.3" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#graph-classification"><i class="fa fa-check"></i><b>9.3.3</b> 图分类</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#pooling-with-mapper-on-graphs-and-data-classification"><i class="fa fa-check"></i><b>9.4</b> 在图上用映射器（mapper）算法池化和数据分类</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-and-edge-features"><i class="fa fa-check"></i><b>9.4.1</b> 网格分类</a></li>
<li class="chapter" data-level="9.4.2" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-features-only"><i class="fa fa-check"></i><b>9.4.2</b> 网格分类：仅带输入顶点特征的CC-pooling</a></li>
<li class="chapter" data-level="9.4.3" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#point-cloud-classification-cc-pooling-with-input-vertex-features-only"><i class="fa fa-check"></i><b>9.4.3</b> 点云分类：仅带输入顶点特征得CC-pooling</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="implementation-and-numerical-results.html"><a href="implementation-and-numerical-results.html#ablation-studies"><i class="fa fa-check"></i><b>9.5</b> 消融实验</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="related-work.html"><a href="related-work.html"><i class="fa fa-check"></i><b>10</b> 相关工作</a>
<ul>
<li class="chapter" data-level="10.1" data-path="related-work.html"><a href="related-work.html#graph-based-models"><i class="fa fa-check"></i><b>10.1</b> 基于图的模型</a></li>
<li class="chapter" data-level="10.2" data-path="related-work.html"><a href="related-work.html#attention-based-models"><i class="fa fa-check"></i><b>10.2</b> 基于注意力的模型</a></li>
<li class="chapter" data-level="10.3" data-path="related-work.html"><a href="related-work.html#graph-based-pooling"><i class="fa fa-check"></i><b>10.3</b> 基于图的池化</a></li>
<li class="chapter" data-level="10.4" data-path="related-work.html"><a href="related-work.html#applied-algebraic-topology"><i class="fa fa-check"></i><b>10.4</b> 代数拓扑的应用</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i><b>11</b> 结论</a></li>
<li class="appendix"><span><b>附录</b></span></li>
<li class="chapter" data-level="A" data-path="glossary.html"><a href="glossary.html"><i class="fa fa-check"></i><b>A</b> 术语</a></li>
<li class="chapter" data-level="B" data-path="lifting-maps.html"><a href="lifting-maps.html"><i class="fa fa-check"></i><b>B</b> 提升映射</a>
<ul>
<li class="chapter" data-level="B.1" data-path="lifting-maps.html"><a href="lifting-maps.html#n-hop-cc-of-a-graph"><i class="fa fa-check"></i><b>B.1</b> 图的n-hop CC</a></li>
<li class="chapter" data-level="B.2" data-path="lifting-maps.html"><a href="lifting-maps.html#path-based-and-subgraph-based-cc-of-a-graph"><i class="fa fa-check"></i><b>B.2</b> 图的基于路径和基于子图的CC</a></li>
<li class="chapter" data-level="B.3" data-path="lifting-maps.html"><a href="lifting-maps.html#loop-based-cc-of-a-graph"><i class="fa fa-check"></i><b>B.3</b> Loop-based CC of a graph</a></li>
<li class="chapter" data-level="B.4" data-path="lifting-maps.html"><a href="lifting-maps.html#coface-cc-of-a-simplicial-complex-or-of-a-cc"><i class="fa fa-check"></i><b>B.4</b> Coface CC of a simplicial complex or of a CC</a></li>
<li class="chapter" data-level="B.5" data-path="lifting-maps.html"><a href="lifting-maps.html#augmentation-of-ccs-by-higher-rank-cells"><i class="fa fa-check"></i><b>B.5</b> Augmentation of CCs by higher-rank cells</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="ccnn-architecture-search-and-topological-quantum-field-theories.html"><a href="ccnn-architecture-search-and-topological-quantum-field-theories.html"><i class="fa fa-check"></i><b>C</b> CCNN architecture search and topological quantum field theories</a></li>
<li class="chapter" data-level="D" data-path="learning-discrete-exterior-calculus-operators-with-ccanns.html"><a href="learning-discrete-exterior-calculus-operators-with-ccanns.html"><i class="fa fa-check"></i><b>D</b> Learning discrete exterior calculus operators with CCANNs</a></li>
<li class="chapter" data-level="E" data-path="a-mapper-induced-topology-preserving-cc-pooling-operation.html"><a href="a-mapper-induced-topology-preserving-cc-pooling-operation.html"><i class="fa fa-check"></i><b>E</b> A mapper-induced topology-preserving CC-pooling operation</a></li>
<li class="chapter" data-level="" data-path="参考文献.html"><a href="参考文献.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">拓扑深度学习：超越图数据</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="implementation-and-numerical-results" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">第 9 章</span> 实现与实验<a href="implementation-and-numerical-results.html#implementation-and-numerical-results" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>所提出的 CCNNs 可用于为不同的学习任务构建不同的神经网络架构。在本节中，我们将通过评估 CCNNs 在形状分析和图形学习任务中的预测性能来证明其通用性和有效性。在几何处理实验中，我们将 CCNNs 与最先进的方法进行了比较，这些方法针对特定任务进行了高度设计和训练。此外，我们还对几何数据处理中常用的各种数据模式（即点云和三维网格）进行了实验。我们还对图形数据进行了实验。在实验中，我们调整了三个主要部分：CCNN 架构的选择、学习率和数据增强中的副本数量。我们为每项学习任务选择的 CCNN 架构进行了论证。我们在 PyTorch 中实现了我们的流程，并在使用 Microsoft Windows 后端的单 GPU NVIDIA GeForce RTX 3060 Ti 上运行了实验。</p>
<div id="software-toponetx-topoembedx-and-topomodelx" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> 软件：TopoNetX, TopoEmbedX, and TopoModelX<a href="implementation-and-numerical-results.html#software-toponetx-topoembedx-and-topomodelx" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>我们所有的软件开发和实验分析都是使用 Python 进行的。我们也开发了三个 Python 软件包，并用它们来运行我们的实验:</p>
<ul>
<li><p><a href="https://github.com/pyt-team/TopoNetX">TopoNetX</a>，支持构建多种拓扑结构，包括胞腔复形、单纯复形和组合复形类。这些类分别提供了计算胞腔复形、单纯复形和组合复形上的边界算子（ boundary operators）、霍奇拉普拉斯（Hodge Laplacians）和高阶邻接算子的方法；</p></li>
<li><p><a href="https://github.com/pyt-team/TopoEmbedX">TopoEmbedX</a> ，支持对胞腔复形、单纯复形和组合复形的高阶关系进行表征学习（representation learning ）；</p></li>
<li><p><a href="https://github.com/pyt-team/TopoModelX">TopoModelX</a>， 支持计算定义在这些拓扑域上的深度学习模型。</p></li>
</ul>
<p>除了所实现的软件包，我们还使用了 PyTorch <span class="citation">(<a href="#ref-paszke2017automatic">Paszke et al. 2017</a>)</span> 来训练本节中报告的神经网络。此外，我们还利用 Scikit-learn <span class="citation">(<a href="#ref-scikit-learn">Pedregosa et al. 2011</a>)</span> 计算了 1-Hodge Laplacians的特征向量。点云的法向量是使用点云工具包（Point Cloud Utils package）<span class="citation">(<a href="#ref-point-cloud-utils">Williams 2022</a>)</span>计算的。最后，在软件包的开发和计算过程中，我们使用了 NetworkX <span class="citation">(<a href="#ref-hagberg2008exploring">Hagberg, Swart, and S Chult 2008</a>)</span> 和 HyperNetX <span class="citation">(<a href="#ref-joslyn2021hypernetwork">Joslyn et al. 2021</a>)</span>。</p>
</div>
<div id="datasets" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> 数据集<a href="implementation-and-numerical-results.html#datasets" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>在CCNNs的评估实验中，我们使用了四种数据集：Human Body, COSEG, SHREC11, 以及一个用于图分类的标准数据集 <span class="citation">(<a href="#ref-bianchi2020mincutpool">Bianchi, Gallicchio, and Micheli 2022</a>)</span>。数据集的摘要如下：</p>
<p><strong>人体分割数据集，Human Body segmentation dataset</strong>. 文献<span class="citation">(<a href="#ref-atzmon2018point">Atzmon, Maron, and Lipman 2018</a>)</span> 中提出的原始人体分割数据集包含相对较大的网格，网格顶点最多可达 12000 个。该数据集中提供的分割标签是按面(per-face)设置的，分割准确率被定义为正确分类的面数与整个数据集中面总数的比率。在本文项工作中，我们使用了 <span class="citation">(<a href="#ref-hanocka2019meshcnn">Hanocka et al. 2019</a>)</span> 提供的原始人体数据集的简化版本，其中网格的节点数少于 1,000 个，分割标签被重新映射到边上。我们在第 <a href="implementation-and-numerical-results.html#mesh-segmentation">9.3.1</a>节的形状分析（例如，网格分割）任务中使用了这个简化版的人体数据集。</p>
<p><strong>COSEG分割数据集，COSEG segmentation dataset</strong>. 原始 COSEG 数据集<span class="citation">(<a href="#ref-wang2012active">Y. Wang et al. 2012</a>)</span>包含 11 组带有基准真值（ground-true）分割的形状。在本文工作中，我们使用了原始 COSEG 数据集的一个子集，其中包含相对较大的外星人、花瓶和椅子集。这三个数据集分别包含 200、300 和 400 个形状。我们使用这个自定义的 COSEG 数据集子集来完成第 <a href="implementation-and-numerical-results.html#mesh-segmentation">9.3.1</a>节中的形状分析（例如，网格分割）任务。</p>
<p><strong>SHREC11分类数据集，SHREC11 classification dataset</strong>. SHREC 2011 <span class="citation">(<a href="#ref-lian2011shape">Lian et al. 2011</a>)</span>, 简写为SHREC11, 是一个大型数据集，其中包含来自 30 个类别的 600 个非刚性变形形状（水密三角形网格，watertight triangel meshes<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>），每个类别包含相同数量的物体。这些类别包括手、灯、女人、男人、火烈鸟和兔子。该数据集分为训练集和测试集，分别包含 480 个和 120 个形状。我们使用 SHREC11 数据集来完成 <a href="implementation-and-numerical-results.html#mesh-and-point-cloud-classification">9.3.2</a> 和 <a href="implementation-and-numerical-results.html#pooling-with-mapper-on-graphs-and-data-classification">9.4</a>章节中的形状分析任务。</p>
<blockquote>
<p>译者注：水密（watertight）网格通常描述由一个封闭曲面组成的网格，水密网格不包含孔洞并且内部定义明确</p>
</blockquote>
<p><strong>图分类基准数据集</strong>. 该数据集包含属于三个不同类别的图 <span class="citation">(<a href="#ref-bianchi2020mincutpool">Bianchi, Gallicchio, and Micheli 2022</a>)</span>。对于每个图，每个顶点（0-cochain）上的特征向量都是大小为 5 的独热向量，它存储了图上顶点的相对位置。该数据集分为简易版和困难版，简易版包含高度连接的图，而困难版包含稀疏的图。我们在第 <a href="implementation-and-numerical-results.html#graph-classification">9.3.3</a>节的图分类任务中使用了这个数据集。</p>
</div>
<div id="shape-analysis-mesh-segmentation-and-classification" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> 形状分析：网格分割与分类<a href="implementation-and-numerical-results.html#shape-analysis-mesh-segmentation-and-classification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>用于形状分析实验（网格分割和分类）的 CC 结构是由网格的三角剖分简单诱导出来的。具体来说，0-、1-和 2-cells分别是网格的顶点、边和面。用于 CCNN 的矩阵是 <span class="math inline">\(B_{0,1},~B_{0,2}\)</span>、它们的转置矩阵以及（共）邻接矩阵 <span class="math inline">\(A_{1,1}\)</span>、<span class="math inline">\(coA_{1,1}\)</span> 和 <span class="math inline">\(coA_{2,1}\)</span>。</p>
<p>CCNN 将共链向量作为输入特征。对于形状分析任务，我们考虑直接从底层网格的顶点坐标建立特征的共链，我们也注意到还有其他选择（例如 文献<span class="citation">(<a href="#ref-mejia2017spectral">Mejia, Ruiz-Salguero, and Cadavid 2017</a>)</span> 中基于光谱的共链）也可以包括在内。我们的形状分析任务有三个输入共链：顶点共链、边共链和面共链，每个顶点共链有两个输入特征：与顶点相关的位置和法向量（normal vector）。与<span class="citation">(<a href="#ref-hanocka2019meshcnn">Hanocka et al. 2019</a>)</span>类似，每个边共链由五个特征组成：每个面的边长、二面角（dihedral angle）、两个内角和两个边长比。最后，每个输入面共链由三个输入特征组成：面面积、面法线和三个面角度。</p>
<div id="mesh-segmentation" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> 网格分割<a href="implementation-and-numerical-results.html#mesh-segmentation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>对于人体数据集 <span class="citation">(<a href="#ref-maron2017convolutional">Maron et al. 2017</a>)</span>，我们构建了一个 CCNN，它能产生一个边类。架构的张量图如图<a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(a)所示。对于 COSEG 数据集<span class="citation">(<a href="#ref-wang2012active">Y. Wang et al. 2012</a>)</span>，我们构建了一个 CCNN，结合我们提出的定义在顶点、边和面上的特征向量来学习最终的面类。如图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(b)所示，该架构使用关联矩阵以及（共）邻接矩阵来构建信号流。具体来说，张量图显示了三个非平方注意块（non-squared attention-blocks）和三个平方注意块（squared attention blocks）。如图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(b)所示，模型的深度选择为2。</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mesh-net"></span>
<img src="figures/experiment.png" alt="实验中所用的CCNNs的张量图 (a): 用于网格分割任务的 CCNNs. 尤其, $\mbox{CCNN}_{HB}$ 和 $\mbox{CCNN}_{COSEG}$分别是 是人体数据集[@atzmon2018point]和COSEG dataset [@wang2012active]使用的架构。 (b): SHREC11 数据集 [@lian2011shape]使用网格分类CCNN. (c): 数据集[@bianchi2020mincutpool]使用图分类CCNN。 (d): 在 SHREC11 数据集上网格/点云分类 CCNNs与 MOG 算法结合使用."  />
<p class="caption">
图 9.1: 实验中所用的CCNNs的张量图 (a): 用于网格分割任务的 CCNNs. 尤其, <span class="math inline">\(\mbox{CCNN}_{HB}\)</span> 和 <span class="math inline">\(\mbox{CCNN}_{COSEG}\)</span>分别是 是人体数据集<span class="citation">(<a href="#ref-atzmon2018point">Atzmon, Maron, and Lipman 2018</a>)</span>和COSEG dataset <span class="citation">(<a href="#ref-wang2012active">Y. Wang et al. 2012</a>)</span>使用的架构。 (b): SHREC11 数据集 <span class="citation">(<a href="#ref-lian2011shape">Lian et al. 2011</a>)</span>使用网格分类CCNN. (c): 数据集<span class="citation">(<a href="#ref-bianchi2020mincutpool">Bianchi, Gallicchio, and Micheli 2022</a>)</span>使用图分类CCNN。 (d): 在 SHREC11 数据集上网格/点云分类 CCNNs与 MOG 算法结合使用.
</p>
</div>
<p>请注意，为 COSEG 和人体数据集选择的架构具有相同数量和类型的构建模块；比较图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(a) 和 (b). 实验采用 85%-15% 的随机训练-测试比例。对于这两种架构，输出张量都采用了软最大激活（softmax activation），使用 0.0001 的学习率和标准交叉熵损失对所有分割模型进行了 600 次训练，在人体和形状 COSEG 数据集上都采用这些设置。</p>
<p>我们使用Human Body <span class="citation">(<a href="#ref-maron2017convolutional">Maron et al. 2017</a>)</span> 和 Shape COSEG（花瓶、椅子和外星人）<span class="citation">(<a href="#ref-wang2012active">Y. Wang et al. 2012</a>)</span> 数据集对所提出的 CCNN 进行了网格分割测试。对于这些数据集中的每个网格，所使用的 CC 结构是由网格的三角剖分建立的，尽管 CC 结构的其他变化也会产生类似的结果。此外，还为 <span class="math inline">\(0\leq k \leq 2\)</span> 构建了三个 <span class="math inline">\(k\)</span>-cochains，并在 CCNN 训练中使用。如表 <a href="implementation-and-numerical-results.html#tab:shape-xp">9.1</a>所示，在四个数据集中的两个数据集上，CCNN 优于为网格分析量身定制的三个神经网络（HodgeNet <span class="citation">(<a href="#ref-smirnov2021hodgenet">Smirnov and Solomon 2021</a>)</span>, PD-MeshNet <span class="citation">(<a href="#ref-milano2020primal">Milano et al. 2020</a>)</span> 和 MeshCCN <span class="citation">(<a href="#ref-hanocka2019meshcnn">Hanocka et al. 2019</a>)</span>），并且是所有四个数据集上最好的两个神经网络之一。</p>
<table>
<caption><span id="tab:shape-xp">表 9.1: </span>与形状分析相关的测试集，即Human Body和 COSEG（花瓶、椅子、外星人）数据集的预测准确率。本文报告的结果基于 <span class="math inline">\(\mbox{CCNN}_{COSEG}\)</span> 和<span class="math inline">\(\mbox{CCNN}_{HB}\)</span> 架构。其中，第一列报告的是 <span class="math inline">\(\mbox{CCNN}_{HB}\)</span> 的结果，而第二、第三和第四列报告的是 <span class="math inline">\(\mbox{CCNN}_{COSEG}\)</span>的结果。</caption>
<thead>
<tr class="header">
<th align="left">方法</th>
<th align="center">Human Body</th>
<th align="center">COSEG vase</th>
<th align="center">COSEG chair</th>
<th align="center">COSEG alien</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">HodgeNet</td>
<td align="center">85.03</td>
<td align="center">90.30</td>
<td align="center">95.68</td>
<td align="center">96.03</td>
</tr>
<tr class="even">
<td align="left">PD-MeshNet</td>
<td align="center">85.61</td>
<td align="center">95.36</td>
<td align="center">97.23</td>
<td align="center">98.18</td>
</tr>
<tr class="odd">
<td align="left">MeshCNN</td>
<td align="center">85.39</td>
<td align="center">92.36</td>
<td align="center">92.99</td>
<td align="center">96.26</td>
</tr>
<tr class="even">
<td align="left">CCNN</td>
<td align="center">87.30</td>
<td align="center">93.40</td>
<td align="center">98.30</td>
<td align="center">93.70</td>
</tr>
</tbody>
</table>
<p><strong><span class="math inline">\(\mbox{CCNN}_{COSEG}\)</span> 和 <span class="math inline">\(\mbox{CCNN}_{HB}\)</span>的架构</strong>. 在 <span class="math inline">\(\mbox{CCNN}_{COSEG}\)</span>中, 如图<a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(a)所示, 我们选择定义 <a href="push-forward-pooling-and-unpooling.html#def:general-pooling-hoan">7.5</a>中给出的 带池化操作的CCNN 的架构，该架构会推送来自顶点、边和面的信号，并将它们的信息汇总到最终的面预测类中。我们同样选择 <span class="math inline">\(\mbox{CCNN}_{HB}\)</span>，只不过预测的信号是边类。之所以这样选择，是因为Human Body 数据集<span class="citation">(<a href="#ref-atzmon2018point">Atzmon, Maron, and Lipman 2018</a>)</span>对边缘的分割信息进行了编码。</p>
</div>
<div id="mesh-and-point-cloud-classification" class="section level3 hasAnchor" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> 网格和点云分类<a href="implementation-and-numerical-results.html#mesh-and-point-cloud-classification" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>我们使用 SHREC11 数据集<span class="citation">(<a href="#ref-lian2011shape">Lian et al. 2011</a>)</span>对我们的方法针对网格分类进行了评估，该数据集采用和第<a href="implementation-and-numerical-results.html#mesh-segmentation">9.3.1</a>节的分割实验中的相同共链和 CC 结构。用于网格分类任务的 CCNN 架构（表示为<span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span> ）如图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(b)所示。<span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span>的最后一层在图<a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(b)中以灰色节点表示，这是一个简单的池化操作，将CC的所有嵌入映射到相同的欧是空间后求和。<span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span> 使用 <span class="math inline">\(tanh\)</span> 和 <span class="math inline">\(identity\)</span> 激活函数进行了 40 次训练，学习率为 0.005，损失为标准交叉熵。我们使用各向异向扩展和随机旋转来增强数据。每个网格增强 30 次，以质量顶点中心为中心，并重新缩放以适应单位立方体。</p>
<p>带有<span class="math inline">\(identity\)</span> 激活和<span class="math inline">\(\tanh\)</span>激活的<span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span>的预测准确率分别达到96.67%和99.17%。表<a href="implementation-and-numerical-results.html#tab:shrec">9.2</a>显示，CCNNs 的表现优于两个专门用于网格分析的神经网络（HodgeNet 和 MeshCCN），在网格和点云分类方面是仅次于 PD-MeshNet 的最佳模型。值得一提的是，网格分类 CCNN 所需的训练历时（40 个epochs）大大少于网格分割 CCNN（600 个epochs）。</p>
<blockquote>
<p>译者注：Identity激活 是一种输入和输出相等的激活函数，比较适合底层函数是线性的，比如线性回归问题，当存在非线性问题是，作用就大打折扣</p>
</blockquote>
<table>
<caption><span id="tab:shrec">表 9.2: </span>在数据集SHREC11 test 上的预测精度。 左列和右列分别报告了网格和点云分类结果。网格分类的 CCNN 为 <span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span> ，点云分类的 CCNN 为 <span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 。</caption>
<thead>
<tr class="header">
<th align="left">方法</th>
<th align="center">Mesh</th>
<th align="center">Point cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">HodgeNet</td>
<td align="center">99.10</td>
<td align="center">94.70</td>
</tr>
<tr class="even">
<td align="left">PD-MeshNet</td>
<td align="center">99.70</td>
<td align="center">99.10</td>
</tr>
<tr class="odd">
<td align="left">MeshCNN</td>
<td align="center">98.60</td>
<td align="center">91.00</td>
</tr>
<tr class="even">
<td align="left">CCNN</td>
<td align="center">99.17</td>
<td align="center">95.20</td>
</tr>
</tbody>
</table>
<p><strong><span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span>的架构</strong>. <span class="math inline">\(mbox{CCNN}_{SHREC}\)</span>有两层，用作定义<a href="push-forward-pooling-and-unpooling.html#def:general-pooling-hoan">7.5</a>中描述的池化CCNN，类似于<span class="math inline">\(\mbox{CCNN}_{COSEG}\)</span>和<span class="math inline">\(\mbox{CCNN}_{HB}\)</span>。主要区别在于，<span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span> 的最后一层（图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(b)中的灰色点表示）是一个全局池化函数，它将底层 CC 的所有维度（0、1、2）的嵌入映射到相同的欧氏空间后求和。</p>
</div>
<div id="graph-classification" class="section level3 hasAnchor" number="9.3.3">
<h3><span class="header-section-number">9.3.3</span> 图分类<a href="implementation-and-numerical-results.html#graph-classification" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>对于图分类任务，使用文献<span class="citation">(<a href="#ref-bianchi2020mincutpool">Bianchi, Gallicchio, and Micheli 2022</a>)</span>中提供的图分类测试基准数据，该数据集由三类不同标签的数据组成。对于每个图， 每个顶点(0-cochain)的特征向量都是尺寸为5的独热向量，存储了图中顶点的相对位置。 为了构建 CC 结构，我们使用了输入图的 2-clique 复形。 然后，我们继续构建用于图分类的 CCNN，表示为 <span class="math inline">\(\mbox{CCNN}_{Graph}\)</span> 表示，如图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(c)所示。 构造 <span class="math inline">\(\mbox{CCNN}_{Graph}\)</span>的矩阵式 <span class="math inline">\(B_{0,1},~B_{1,2},~B_{0,2}\)</span>，转置矩阵和（共）邻矩阵是<span class="math inline">\(A_{0,1},A_{1,1},~coA_{2,1}\)</span>。 <span class="math inline">\(\mbox{CCNN}_{Graph}\)</span> 的共链构建方式如下对于数据集中的每个图，我们将 0-Cochain 设置为数据集提供的大小为 5的独热向量。这个独热向量存储了顶点在图中的相对位置。我们还通过考虑连接到每个胞腔顶点的独热向量的坐标最大值，在图的 2-clique复形上构建 1-cochain和2-cochain。<span class="math inline">\(\mbox{CCNN}_{graoh}\)</span> 的输入包括作为数据集一部分提供的 0-cochain，以及构建的 1-cochain和 2-cochain。图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(c) 中的灰色节点表示简单的均值池化操作。我们以 0.005 的学习率训练这个网络，并且没有增强数据。</p>
<p>表 <a href="implementation-and-numerical-results.html#tab:wrap-tab">9.3</a>报告了<em>简易</em>和<em>困难</em>两个版本数据集的结果<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>，并将它们与六个最先进的GNN进行了比较。如表<a href="implementation-and-numerical-results.html#tab:wrap-tab">9.3</a>所示，在 “困难”数据集上，CCNN优于所有六种GNN，在 “简易”数据集上，CCNN优于五种GNN。我们提出的 CCNN 在困难数据集上的表现优于 MinCutPool，而在建议数据集上的表现与 MinCutPool 相当。</p>
<table style="width:100%;">
<caption><span id="tab:wrap-tab">表 9.3: </span>在<span class="citation">(<a href="#ref-bianchi2020mincutpool">Bianchi, Gallicchio, and Micheli 2022</a>)</span>测试集上与图分类相关的预测准确率。所有结果均使用 <span class="math inline">\(\mbox{CCNN}_{Graph}\)</span>架构报告。</caption>
<colgroup>
<col width="10%" />
<col width="13%" />
<col width="10%" />
<col width="14%" />
<col width="10%" />
<col width="11%" />
<col width="17%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">数据集</th>
<th align="center">Graclus</th>
<th align="center">NDP</th>
<th align="center">DiffPool</th>
<th align="center">Top-K</th>
<th align="left">SAGPool</th>
<th align="center">MinCutPool</th>
<th align="center">CCNN</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Easy</td>
<td align="center">97.81</td>
<td align="center">97.93</td>
<td align="center">98.64</td>
<td align="center">82.47</td>
<td align="left">84.23</td>
<td align="center">99.02</td>
<td align="center">98.90</td>
</tr>
<tr class="even">
<td align="left">Hard</td>
<td align="center">69.08</td>
<td align="center">72.67</td>
<td align="center">69.98</td>
<td align="center">42.80</td>
<td align="left">37.71</td>
<td align="center">73.80</td>
<td align="center">75.59</td>
</tr>
</tbody>
</table>
<p><strong><span class="math inline">\(\mbox{CCNN}_{Graph}\)</span>的架构</strong>. 对于图<a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(c)中给出的<span class="math inline">\(\mbox{CCNN}_{Graph}\)</span>， 我们选择了定义<a href="push-forward-pooling-and-unpooling.html#def:general-pooling-hoan">7.5</a>中给出的 CCNN 池架构，该架构推送来自顶点、边和面的信号，并在做出最终预测之前将它们的信息聚合到高阶胞腔。对于<span class="citation">(<a href="#ref-bianchi2020mincutpool">Bianchi, Gallicchio, and Micheli 2022</a>)</span>中的数据集，我们用两种架构进行了实验：第一种架构与图<a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(b)中所示的<span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span>相同，第二种架构是图<a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(c)中所示的<span class="math inline">\(\mbox{CCNN}_{Graph}\)</span>。我们报告的是 <span class="math inline">\(\mbox{CCNN}_{Graph}\)</span>的实验结果，因为它的性能更优。需要注意的是，当这种神经网络在底层单纯复形上执行时，通常不会考虑关联矩阵 <span class="math inline">\(B_{0,1}\)</span> and <span class="math inline">\(B_{1,3}\)</span>，但是配备了这些额外关联矩阵的 CC 结构有助于提高 <span class="math inline">\(\mbox{CCNN}_{Graph}\)</span> 的泛化性能。</p>
</div>
</div>
<div id="pooling-with-mapper-on-graphs-and-data-classification" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> 在图上用映射器（mapper）算法池化和数据分类<a href="implementation-and-numerical-results.html#pooling-with-mapper-on-graphs-and-data-classification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>我们通过实验来评估第 <a href="push-forward-pooling-and-unpooling.html#mapper-and-the-cc-pooling-operation">7.4</a>节中讨论的MOG池化操作策略的有效性。回顾一下，MOG 算法需要两部分输入：CC <span class="math inline">\(\mathcal{X}\)</span> 的 1-skeleton和 <span class="math inline">\(\mathcal{X}\)</span> 顶点上的标量函数。我们选择的输入标量函数是平均测地距离（Average geodesic distance，AGD）<span class="citation">(<a href="#ref-KimLipmanChen2010">V. G. Kim et al. 2010</a>)</span>，它与反射和旋转无关，因此适用于形状检测。对于图上的两个实体 <span class="math inline">\(u\)</span> 和 <span class="math inline">\(v\)</span>，使用 Dijkstra 的最短路径算法计算出 <span class="math inline">\(u\)</span> 和 <span class="math inline">\(v\)</span> 之间的测地距离，用 <span class="math inline">\(d(v,u)\)</span> 表示。AGD 的计算公式如下：
<span class="math display" id="eq:agd">\[\begin{equation}
AGD(v)=\frac{1}{|V|}\sum_{u\in V}d(v,u).
\tag{9.1}
\end{equation}\]</span></p>
<p>从公式 <a href="implementation-and-numerical-results.html#eq:agd">(9.1)</a>可以看出，靠近图中心的顶点可能具有较低的函数值，而位于外围的点可能具有较高的函数值。这一观察结果已被用于研究图的对称性<span class="citation">(<a href="#ref-KimLipmanChen2010">V. G. Kim et al. 2010</a>)</span>，并为 MOG 池化策略选择 AGD 提供了理由。图 <a href="implementation-and-numerical-results.html#fig:pooling-examples">9.2</a> 展示了在 SHREC11 数据集上使用 带AGD的MOG 池化策略的几个示例。</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pooling-examples"></span>
<img src="figures/pooling_examples.png" alt="在数据集SHREC11上[@lian2011shape]使用MOG算法的示例。 在每幅图中，我们左边显示的是原始网格图，右边显示的是映射图。MOG 算法选择的标量函数是平均测地距离（AGD）。我们观察到，池化后的映射图与原始图的整体形状相似."  />
<p class="caption">
图 9.2: 在数据集SHREC11上<span class="citation">(<a href="#ref-lian2011shape">Lian et al. 2011</a>)</span>使用MOG算法的示例。 在每幅图中，我们左边显示的是原始网格图，右边显示的是映射图。MOG 算法选择的标量函数是平均测地距离（AGD）。我们观察到，池化后的映射图与原始图的整体形状相似.
</p>
</div>
<p>为了证明我们的 MOG 池化方法的有效性，我们在 SHREC11 数据集上进行了三项实验： 基于输入顶点和边缘特征的 CC-pooing网格分类（参见第 <a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-and-edge-features">9.4.1</a>节）、基于仅输入顶点特征的 CC-pooing的网格分类（参见第<a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-features-only">9.4.2</a>节）和基于仅输入顶点特征的 CC-pooling点云分类（第 <a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-features-only">9.4.2</a>节）、 以及基于仅输入顶点特征的 CC 汇集的点云分类（参见第@ref(point-cloud-classification-cc-pooling-with-input-vertex-features-only）节）。在<a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-and-edge-features">9.4.1</a>和 <a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-features-only">9.4.2</a> 节中的实验利用了SHREC11数据集中的网格结构，而 <a href="implementation-and-numerical-results.html#point-cloud-classification-cc-pooling-with-input-vertex-features-only">9.4.3</a> 节中的实验则利用了自己的点云版本。特别是，我们选择了两个简单的 CCNN 架构，如图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(d)所示，分别用 <span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span> 和 <span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 表示，而不是图 Figure <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(b)中更为复杂的 <span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span> 架构。<span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span> 和 <span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 之间的主要区别在于输入特征向量的选择，这将在下文中介绍。</p>
<div id="mesh-classification-cc-pooling-with-input-vertex-and-edge-features" class="section level3 hasAnchor" number="9.4.1">
<h3><span class="header-section-number">9.4.1</span> 网格分类<a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-and-edge-features" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>在本实验中，我们将顶点特征向量视为底层网格中每个顶点的位置与法向量的连接。对于边缘特征，我们计算了 1-Hodge Laplacian <span class="citation">(<a href="#ref-dodziuk1976finite">Dodziuk 1976</a>; <a href="#ref-eckmann1944harmonische">Eckmann 1944</a>)</span>的前十个特征向量，并为底层网格的边缘附加了一个 10 维特征向量。我们在此考虑的 CC 是三维的，因为它由三角形网格（顶点、边和面）和 3-cells组成。3-cells通过 MOG 算法获得，用于增强每个网格。 我们使用 AGD 标量函数作为输入，通过 MOG 算法计算 3-cells。 我们使用通过张量图<span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span>定义的 CCNN 进行了这项实验，张量图见图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(d)。在训练过程中，我们为每个网格添加了 10 个附加网格，每个附加网格都是通过随机旋转以及对顶点位置进行 0.1% 的噪声扰动获得的。我们使用 0.0002 的学习率和标准交叉熵损失对 <span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span> 进行了 100 次训练，获得了 98.1% 的准确率。虽然 <span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span> 的准确率低于我们在表<a href="implementation-and-numerical-results.html#tab:shrec">9.2</a>中报告的 <span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span> 的准确率（99. 17%），但我们注意到，<span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span> 要达到类似的准确率，网格增强所需的重复次数要少得多（<span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span> 需要 10 次重复，而 <span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span> 需要 30 次重复）。</p>
<p><strong><span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span>架构</strong>. 图<a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(d)中的张量图<span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span>对应于池化CCNN。 特别是，<span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span> 将信号推向两个不同的高阶胞腔：网格面以及从 MOG 算法中获得的 3-cells。</p>
</div>
<div id="mesh-classification-cc-pooling-with-input-vertex-features-only" class="section level3 hasAnchor" number="9.4.2">
<h3><span class="header-section-number">9.4.2</span> 网格分类：仅带输入顶点特征的CC-pooling<a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-features-only" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>在本实验中，我们考虑输入顶点的位置和范数向量。
我们所考虑的 CC 结构是从每个网格中获得的底层图结构；也就是说，我们只使用顶点和边，而忽略面。我们使用 AGD 标量函数作为输入，通过 MOG 算法获得的 2-cells来增强这一结构。我们选择了比 <span class="math inline">\(\mbox{CCNN}_{MOG1}\)</span> 相对简单的网络结构，并在图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(d)中报告为 <span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span>。在训练过程中，我们为每个网格添加了 10 个额外的网格，每个额外的网格都是通过随机旋转以及对顶点位置进行 0.05% 的噪声扰动获得的。我们使用 0.0003 的学习率和标准交叉熵损失对 <span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 进行了 100 次训练，并获得了 97.1% 的准确率。</p>
<p><strong>用于网格分类的<span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span>架构</strong>. 图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(d) 中的张量图 <span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 对应的是池化 CCNN。尤其，<span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 将信号推向从 MOG 算法中获得的单个 2-cell。请注意，<span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 的整体架构在原理上与 AlexNet <span class="citation">(<a href="#ref-krizhevsky2017imagenet">Krizhevsky, Sutskever, and Hinton 2017</a>)</span> 相似，即卷积层之后是池化层。</p>
</div>
<div id="point-cloud-classification-cc-pooling-with-input-vertex-features-only" class="section level3 hasAnchor" number="9.4.3">
<h3><span class="header-section-number">9.4.3</span> 点云分类：仅带输入顶点特征得CC-pooling<a href="implementation-and-numerical-results.html#point-cloud-classification-cc-pooling-with-input-vertex-features-only" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>在本实验中，我们考虑在 SHREC11 数据集上进行点云分类。实验设置与第<a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-features-only">9.4.2</a> 节中研究的原理类似，我们只将点云顶点上支持的特征作为输入。 具体来说，对于 SHREC11 数据集中的每个网格，我们从网格表面采样 1000 个点。此外，我们还使用点云工具包（Point Cloud Utils package）<span class="citation">(<a href="#ref-point-cloud-utils">Williams 2022</a>)</span>估算了所得点云的法向量（normal vector）。 为了构建 CC 结构，我们首先考虑从每个点云中获取的 <span class="math inline">\(k\)</span> 最近邻居图（ 设置<span class="math inline">\(k=7\)</span>）。然后，我们使用 AGD 标量函数作为输入，通过 MOG 算法获得的 2-cells对该图进行扩充。我们训练的 <span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 如图 <a href="implementation-and-numerical-results.html#fig:mesh-net">9.1</a>(d)所示在训练过程中，我们为每个点云添加了 12 个额外的实例，每个实例都是通过随机旋转获得的。我们使用 0.0003 的学习率和标准交叉熵损失对 <span class="math inline">\(mbox{CCNN}_{MOG2}\)</span> 进行了 100 次训练，并获得了 95.2% 的准确率（见表<a href="implementation-and-numerical-results.html#tab:shrec">9.2</a>）。</p>
</div>
</div>
<div id="ablation-studies" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> 消融实验<a href="implementation-and-numerical-results.html#ablation-studies" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>在本节中，我们将进行两项消融研究。第一项消融研究表明，CCNN 中的池化策略对预测性能有至关重要的影响。第二项消融研究表明，CCNN 比 GNN 具有更好的预测能力；CCNN 的优势来自其拓扑池化操作以及从拓扑特征中学习的能力。</p>
<p><strong>CCNNs中得池化策略</strong>. 为了评估池化策略的选择对预测性能的影响，我们使用 SHREC11 分类数据集试验了两种池化策略。 第一种池化策略是第<a href="implementation-and-numerical-results.html#pooling-with-mapper-on-graphs-and-data-classification">9.4</a>节中描述的 MOG 算法；第 <a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-features-only">9.4.2</a> 节讨论了基于 <span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 的这种池化策略的结果（97.1%）。 第二种池化策略简述如下。对于每个网格，我们考虑将每个 1-hop邻域视为 CC 中的 1-cells，将每个 2-hop邻域视为 CC 中的 2-cells，从而得到 2 维 CC。我们训练了 <span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span>，得到了 89.2% 的准确率，但是低于 97.1%。这些实验表明，池化策略的选择对预测性能有着至关重要的影响。</p>
<p><strong>比较 CCNN 与 GNN 的预测性能</strong>. 请注意，<span class="math inline">\(\mbox{CCNN}_{SHREC}\)</span> 的输入是一维和二维拓扑特征。 另一方面，<span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span> 的输入只有顶点特征，但它通过使用前推操作，将信号从 0-cells推向从 MOG 算法中获得的 2-cells，从而学习高阶胞腔潜在特征。 在这两种情况下，使用高阶结构对提高预测性能都至关重要，尽管在利用高阶结构方面采用了两种不同的策略。 为了支持我们的说法，我们进行了一项实验，用<span class="math inline">\(A_{0,1}\)</span>诱导的共链算子替换<span class="math inline">\(\mbox{CCNN}_{MOG2}\)</span>中的池化操作层，从而有效地将神经网络转化为 GNN。在这种情况下，使用与实验 <a href="implementation-and-numerical-results.html#mesh-classification-cc-pooling-with-input-vertex-features-only">9.4.2</a>相同的设置，我们获得了 84.56% 的准确率。这个实验揭示了采用高阶结构的性能优势，可以利用高阶胞腔支持的输入拓扑特征，也可以通过增强高阶胞腔的池化策略。</p>

</div>
</div>
<h3>参考文献<a href="参考文献.html#参考文献" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-atzmon2018point" class="csl-entry">
Atzmon, Matan, Haggai Maron, and Yaron Lipman. 2018. <span>“Point Convolutional Neural Networks by Extension Operators.”</span> <em>ACM Transactions on Graphics</em> 37 (4).
</div>
<div id="ref-bianchi2020mincutpool" class="csl-entry">
Bianchi, Filippo Maria, Claudio Gallicchio, and Alessio Micheli. 2022. <span>“Pyramidal Reservoir Graph Neural Network.”</span> <em>Neurocomputing</em> 470: 389–404.
</div>
<div id="ref-dodziuk1976finite" class="csl-entry">
Dodziuk, Jozef. 1976. <span>“Finite-Difference Approach to the <span>H</span>odge Theory of Harmonic Forms.”</span> <em>American Journal of Mathematics</em> 98 (1): 79–104.
</div>
<div id="ref-eckmann1944harmonische" class="csl-entry">
Eckmann, Beno. 1944. <span>“Harmonische Funktionen Und Randwertaufgaben in Einem Komplex.”</span> <em>Commentarii Mathematici Helvetici</em> 17 (1): 240–55.
</div>
<div id="ref-hagberg2008exploring" class="csl-entry">
Hagberg, Aric, Pieter Swart, and Daniel S Chult. 2008. <span>“Exploring Network Structure, Dynamics, and Function Using <span>N</span>etwork<span>X</span>.”</span> Los Alamos National Lab (LANL), Los Alamos, NM (United States).
</div>
<div id="ref-hanocka2019meshcnn" class="csl-entry">
Hanocka, Rana, Amir Hertz, Noa Fish, Raja Giryes, Shachar Fleishman, and Daniel Cohen-Or. 2019. <span>“Mesh<span>CNN</span>: A Network with an Edge.”</span> <em>ACM Transactions on Graphics</em> 38 (4): 1–12.
</div>
<div id="ref-joslyn2021hypernetwork" class="csl-entry">
Joslyn, Cliff A, Sinan G Aksoy, Tiffany J Callahan, Lawrence E Hunter, Brett Jefferson, Brenda Praggastis, Emilie Purvine, and Ignacio J Tripodi. 2021. <span>“Hypernetwork Science: From Multidimensional Networks to Computational Topology.”</span> In <em>Unifying Themes in Complex Systems x: Proceedings of the Tenth International Conference on Complex Systems</em>, 377–92. Springer.
</div>
<div id="ref-KimLipmanChen2010" class="csl-entry">
Kim, Vladimir G, Yaron Lipman, Xiaobai Chen, and Thomas Funkhouser. 2010. <span>“Möbius Transformations for Global Intrinsic Symmetry Analysis.”</span> <em>Computer Graphics Forum</em> 29 (5): 1689–1700.
</div>
<div id="ref-krizhevsky2017imagenet" class="csl-entry">
Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2017. <span>“Imagenet Classification with Deep Convolutional Neural Networks.”</span> <em>Communications of the ACM</em> 60 (6): 84–90.
</div>
<div id="ref-lian2011shape" class="csl-entry">
Lian, Z., A. Godil, B. Bustos, M Daoudi, J. Hermans, S. Kawamura, Y. Kurita, G. Lavoua, P. Dp Suetens, et al. 2011. <span>“Shape Retrieval on Non-Rigid 3<span>D</span> Watertight Meshes.”</span> In <em>Eurographics Workshop on 3d Object Retrieval (3DOR)</em>. Citeseer.
</div>
<div id="ref-maron2017convolutional" class="csl-entry">
Maron, Haggai, Meirav Galun, Noam Aigerman, Miri Trope, Nadav Dym, Ersin Yumer, Vladimir G Kim, and Yaron Lipman. 2017. <span>“Convolutional Neural Networks on Surfaces via Seamless Toric Covers.”</span> <em>ACM Transactions on Graphics</em> 36 (4): 71–71.
</div>
<div id="ref-mejia2017spectral" class="csl-entry">
Mejia, Daniel, Oscar Ruiz-Salguero, and Carlos A. Cadavid. 2017. <span>“Spectral-Based Mesh Segmentation.”</span> <em>International Journal on Interactive Design and Manufacturing</em> 11 (3): 503–14.
</div>
<div id="ref-milano2020primal" class="csl-entry">
Milano, Francesco, Antonio Loquercio, Antoni Rosinol, Davide Scaramuzza, and Luca Carlone. 2020. <span>“Primal-Dual Mesh Convolutional Neural Networks.”</span> <em>Conference on Neural Information Processing Systems</em> 33: 952–63.
</div>
<div id="ref-paszke2017automatic" class="csl-entry">
Paszke, Adam, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017. <span>“Automatic Differentiation in <span>P</span>y<span>T</span>orch.”</span> In <em>NIPS Workshop</em>.
</div>
<div id="ref-scikit-learn" class="csl-entry">
Pedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. <span>“Scikit-Learn: Machine Learning in <span>P</span>ython.”</span> <em>Jmlr</em> 12: 2825–30.
</div>
<div id="ref-smirnov2021hodgenet" class="csl-entry">
Smirnov, Dmitriy, and Justin Solomon. 2021. <span>“Hodge<span>N</span>et: Learning Spectral Geometry on Triangle Meshes.”</span> <em>ACM Transactions on Graphics</em> 40 (4): 1–11.
</div>
<div id="ref-wang2012active" class="csl-entry">
Wang, Yunhai, Shmulik Asafi, Oliver Van Kaick, Hao Zhang, Daniel Cohen-Or, and Baoquan Chen. 2012. <span>“Active Co-Analysis of a Set of Shapes.”</span> <em>ACM Transactions on Graphics</em> 31 (6): 1–10.
</div>
<div id="ref-point-cloud-utils" class="csl-entry">
Williams, Francis. 2022. <span>“Point <span>C</span>loud <span>U</span>tils.”</span>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>水密（watertight）网格通常描述由一个封闭曲面组成的网格，水密网格不包含孔洞并且内部定义明确<a href="implementation-and-numerical-results.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>这些数据集的难度受图簇紧凑程度的控制；“简易”数据中的簇具有更多的簇间连接，而 “困难”数据中的簇更加孤立<span class="citation">(<a href="#ref-bianchi2020mincutpool">Bianchi, Gallicchio, and Micheli 2022</a>)</span><a href="implementation-and-numerical-results.html#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hasse-graph-interpretation-of-ccnns-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="related-work.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/pyt-team/tdlbook/edit/main/rmd/09-implementation-and-numerical-experiments.rmd",
"text": "编辑"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
