---
output:
  pdf_document: default
  html_document: default
---
# (PART\*) 第四部分：应用，文献和结论 {-}

# 实现与实验{#implementation-and-numerical-results}

所提出的 CCNNs 可用于为不同的学习任务构建不同的神经网络架构。在本节中，我们将通过评估 CCNNs 在形状分析和图形学习任务中的预测性能来证明其通用性和有效性。在几何处理实验中，我们将 CCNNs 与最先进的方法进行了比较，这些方法针对特定任务进行了高度设计和训练。此外，我们还对几何数据处理中常用的各种数据模式（即点云和三维网格）进行了实验。我们还对图形数据进行了实验。在实验中，我们调整了三个主要部分：CCNN 架构的选择、学习率和数据增强中的副本数量。我们为每项学习任务选择的 CCNN 架构进行了论证。我们在 PyTorch 中实现了我们的流程，并在使用 Microsoft Windows 后端的单 GPU NVIDIA GeForce RTX 3060 Ti 上运行了实验。

## 软件：TopoNetX, TopoEmbedX, and TopoModelX{#software-toponetx-topoembedx-and-topomodelx}

我们所有的软件开发和实验分析都是使用 Python 进行的。我们也开发了三个 Python 软件包，并用它们来运行我们的实验: 

+ [TopoNetX](https://github.com/pyt-team/TopoNetX)，支持构建多种拓扑结构，包括胞腔复形、单纯复形和组合复形类。这些类分别提供了计算胞腔复形、单纯复形和组合复形上的边界算子（ boundary operators）、霍奇拉普拉斯（Hodge Laplacians）和高阶邻接算子的方法；

+ [TopoEmbedX](https://github.com/pyt-team/TopoEmbedX) ，支持对胞腔复形、单纯复形和组合复形的高阶关系进行表征学习（representation learning ）；

+ [TopoModelX](https://github.com/pyt-team/TopoModelX)， 支持计算定义在这些拓扑域上的深度学习模型。

除了所实现的软件包，我们还使用了 PyTorch [@paszke2017automatic] 来训练本节中报告的神经网络。此外，我们还利用 Scikit-learn [@scikit-learn] 计算了 1-Hodge Laplacians的特征向量。点云的法向量是使用点云工具包（Point Cloud Utils package）[@point-cloud-utils]计算的。最后，在软件包的开发和计算过程中，我们使用了 NetworkX [@hagberg2008exploring] 和 HyperNetX [@joslyn2021hypernetwork]。

## 数据集{#datasets}

在CCNNs的评估实验中，我们使用了四种数据集：Human Body, COSEG, SHREC11, 以及一个用于图分类的标准数据集 [@bianchi2020mincutpool]。数据集的摘要如下：

**人体分割数据集，Human Body segmentation dataset**. 文献[@atzmon2018point] 中提出的原始人体分割数据集包含相对较大的网格，网格顶点最多可达 12000 个。该数据集中提供的分割标签是按面(per-face)设置的，分割准确率被定义为正确分类的面数与整个数据集中面总数的比率。在本文项工作中，我们使用了 [@hanocka2019meshcnn] 提供的原始人体数据集的简化版本，其中网格的节点数少于 1,000 个，分割标签被重新映射到边上。我们在第 \@ref(mesh-segmentation)节的形状分析（例如，网格分割）任务中使用了这个简化版的人体数据集。

**COSEG分割数据集，COSEG segmentation dataset**. 原始 COSEG 数据集[@wang2012active]包含 11 组带有基准真值（ground-true）分割的形状。在本文工作中，我们使用了原始 COSEG 数据集的一个子集，其中包含相对较大的外星人、花瓶和椅子集。这三个数据集分别包含 200、300 和 400 个形状。我们使用这个自定义的 COSEG 数据集子集来完成第 \@ref(mesh-segmentation)节中的形状分析（例如，网格分割）任务。

**SHREC11分类数据集，SHREC11 classification dataset**. SHREC 2011 [@lian2011shape], 简写为SHREC11, 是一个大型数据集，其中包含来自 30 个类别的 600 个非刚性变形形状（水密三角形网格，watertight triangel meshes^[水密（watertight）网格通常描述由一个封闭曲面组成的网格，水密网格不包含孔洞并且内部定义明确]），每个类别包含相同数量的物体。这些类别包括手、灯、女人、男人、火烈鸟和兔子。该数据集分为训练集和测试集，分别包含 480 个和 120 个形状。我们使用 SHREC11 数据集来完成 \@ref(mesh-and-point-cloud-classification) 和  \@ref(pooling-with-mapper-on-graphs-and-data-classification)章节中的形状分析任务。

>译者注：水密（watertight）网格通常描述由一个封闭曲面组成的网格，水密网格不包含孔洞并且内部定义明确

**图分类基准数据集**. 该数据集包含属于三个不同类别的图 [@bianchi2020mincutpool]。对于每个图，每个顶点（0-cochain）上的特征向量都是大小为 5 的独热向量，它存储了图上顶点的相对位置。该数据集分为简易版和困难版，简易版包含高度连接的图，而困难版包含稀疏的图。我们在第 \@ref(graph-classification)节的图分类任务中使用了这个数据集。

## 形状分析：网格分割与分类{#shape-analysis-mesh-segmentation-and-classification}

用于形状分析实验（网格分割和分类）的 CC 结构是由网格的三角剖分简单诱导出来的。具体来说，0-、1-和 2-cells分别是网格的顶点、边和面。用于 CCNN 的矩阵是 $B_{0,1},~B_{0,2}$、它们的转置矩阵以及（共）邻接矩阵 $A_{1,1}$、$coA_{1,1}$ 和 $coA_{2,1}$。

CCNN 将共链向量作为输入特征。对于形状分析任务，我们考虑直接从底层网格的顶点坐标建立特征的共链，我们也注意到还有其他选择（例如 文献[@mejia2017spectral] 中基于光谱的共链）也可以包括在内。我们的形状分析任务有三个输入共链：顶点共链、边共链和面共链，每个顶点共链有两个输入特征：与顶点相关的位置和法向量（normal vector）。与[@hanocka2019meshcnn]类似，每个边共链由五个特征组成：每个面的边长、二面角（dihedral angle）、两个内角和两个边长比。最后，每个输入面共链由三个输入特征组成：面面积、面法线和三个面角度。

### 网格分割{#mesh-segmentation}

对于人体数据集 [@maron2017convolutional]，我们构建了一个 CCNN，它能产生一个边类。架构的张量图如图\@ref(fig:mesh-net)(a)所示。对于 COSEG 数据集[@wang2012active]，我们构建了一个 CCNN，结合我们提出的定义在顶点、边和面上的特征向量来学习最终的面类。如图 \@ref(fig:mesh-net)(b)所示，该架构使用关联矩阵以及（共）邻接矩阵来构建信号流。具体来说，张量图显示了三个非平方注意块（non-squared attention-blocks）和三个平方注意块（squared attention blocks）。如图 \@ref(fig:mesh-net)(b)所示，模型的深度选择为2。

```{r mesh-net, echo=FALSE, fig.align="center", fig.cap="实验中所用的CCNNs的张量图 (a): The CCNNs used in the mesh segmentation tasks. In particular, $\\mbox{CCNN}_{HB}$ and $\\mbox{CCNN}_{COSEG}$ are the architectures used on the Human Body dataset [@atzmon2018point] and on the COSEG dataset [@wang2012active], respectively. (b): The mesh classification CCNN used on the SHREC11 dataset [@lian2011shape]. (c): The graph classification CCNN used on the dataset provided in [@bianchi2020mincutpool]. (d): The mesh/point cloud classification CCNNs used in conjunction with the MOG algorithm on the SHREC11 dataset."}
knitr::include_graphics('figures/experiment.png', dpi=NA)
```

Note that the architectures chosen for the COSEG and for the Human Body datasets have the same number and types of building blocks; compare Figures \@ref(fig:mesh-net)(a) and (b). We use a random 85%-15% train-test split. For both of these architectures, a softmax activation is applied to the output tensor. All our segmentation models are trained for 600 epochs using a learning rate of 0.0001 and the standard cross-entropy loss. These results are consistent across Human Body and Shape COSEG datasets.

We test the proposed CCNNs on mesh segmentation using the Human Body [@maron2017convolutional] and the Shape COSEG (vase, chair, and alien) [@wang2012active] datasets. For each mesh in these datasets, the utilized CC structure is the one induced by the triangulation of the meshes, although other variations in the CC structure yield comparable results. Further, three $k$-cochains are constructed for $0\leq k \leq 2$ and are utilized in CCNN training. As shown in Table \@ref(tab:shape-xp), CCNNs outperform three neural networks tailored to mesh analysis (HodgeNet [@smirnov2021hodgenet], PD-MeshNet [@milano2020primal] and MeshCCN [@hanocka2019meshcnn]) on two out of four datasets, and are among the best two neural networks on all four datasets.

```{r shape-xp, echo=FALSE}
methods <- c('HodgeNet', 'PD-MeshNet', 'MeshCNN', 'CCNN')
hb <- c('85.03', '85.61', '85.39', '87.30')
cosegv <- c('90.30', '95.36', '92.36', '93.40')
cosegc <- c('95.68', '97.23', '92.99', '98.30')
cosega <- c('96.03', '98.18', '96.26', '93.70')
domains <- data.frame(methods, hb, cosegv, cosegc, cosega)
colnames(domains) <- c('Method', 'Human Body', 'COSEG vase', 'COSEG chair', 'COSEG alien')
knitr::kable(domains, align=c('l', 'c', 'c', 'c', 'c'), booktabs=TRUE, caption="Predictive accuracy on test sets related to shape analysis, namely on Human Body and COSEG (vase, chair, alien) datasets. The results reported here are based on the $\\mbox{CCNN}_{COSEG}$ and $\\mbox{CCNN}_{HB}$ architectures. In particular, the result for $\\mbox{CCNN}_{HB}$ is reported in the first column, whereas the results for $\\mbox{CCNN}_{COSEG}$ are reported in the second, third and forth columns.")
```

**Architecture of $\mbox{CCNN}_{COSEG}$ and  $\mbox{CCNN}_{HB}$**. In $\mbox{CCNN}_{COSEG}$, as shown in Figure \@ref(fig:mesh-net)(a), we choose a CCNN pooling architecture as given in Definition \@ref(def:general-pooling-hoan), which pushes signals from vertices, edges and faces, and aggregates their information towards the final face prediction class. We choose $\mbox{CCNN}_{HB}$ similarly, except that the predicted signal is an edge class. The reason for this choice is that the Human Body dataset [@atzmon2018point] encodes the segmentation information on edges.

### Mesh and point cloud classification

We evaluate our method on mesh classification using the SHREC11 dataset [@lian2011shape] based on the same cochains and CC structure used in the segmentation experiment of Section \@ref(mesh-segmentation). The CCNN architecture for our mesh classification task, denoted by $\mbox{CCNN}_{SHREC}$, is demonstrated in Figure \@ref(fig:mesh-net)(b). The final layer of $\mbox{CCNN}_{SHREC}$, depicted as a grey node in Figure \@ref(fig:mesh-net)(b), is a simple pooling operation that sums all embeddings of the CC after mapping them to the same Euclidean space. The $\mbox{CCNN}_{SHREC}$ is trained for 40 epochs with both tanh and identity activation functions using a learning rate of 0.005 and the standard cross-entropy loss. We use anisotropic scaling and random rotations for data augmentation. Each mesh is augmented 30 times, is centered around the vertex center of the mass, and is rescaled to fit inside the unit cube.

The $\mbox{CCNN}_{SHREC}$ with identity activations and $\tanh$ activations achieve predictive accuracies of 96.67% and 99.17%, respectively. Table \@ref(tab:shrec) shows that CCNNs outperform two neural networks tailored to mesh analysis (HodgeNet and MeshCCN), being the second best model behind PD-MeshNet in mesh and point cloud classification. It is worth mentioning that the mesh classification CCNN requires a significantly lower number of epochs to train (40 epochs) as compared to the mesh segmentation CCNNs (600 epochs).

```{r shrec, echo=FALSE}
methods <- c('HodgeNet', 'PD-MeshNet', 'MeshCNN', 'CCNN')
mesh <- c('99.10', '99.70', '98.60', '99.17')
pointcloud <- c('94.70', '99.10', '91.00', '95.20')
domains <- data.frame(methods, mesh, pointcloud)
colnames(domains) <- c('Method', 'Mesh', 'Point cloud')
knitr::kable(domains, align=c('l', 'c', 'c'), booktabs=TRUE, caption="Predictive accuracy on the SHREC11 test dataset. The left and right column report the mesh and point cloud classification results, respectively. The CCNN for mesh classification is $\\mbox{CCNN}_{SHREC}$, while the CCNN for point cloud classification is $\\mbox{CCNN}_{MOG2}$.")
```

**Architecture of $\mbox{CCNN}_{SHREC}$**. The $\mbox{CCNN}_{SHREC}$ has two layers and is chosen as a pooling CCNN in the sense of Definition \@ref(def:general-pooling-hoan), similar to $\mbox{CCNN}_{COSEG}$ and $\mbox{CCNN}_{HB}$. The main difference is that the final layer of $\mbox{CCNN}_{SHREC}$, represented by the grey point in Figure \@ref(fig:mesh-net)(b), is a global pooling function that sums all embeddings of all dimensions (zero, one and two) of the underlying CC after mapping them to the same Euclidean space.

### Graph classification

For the graph classification task, we use the graph classification benchmark provided in [@bianchi2020mincutpool]; the dataset consists of graphs with three different labels. For each graph, the feature vector on each vertex (the 0-cochain) is a one-hot vector of size five, and it stores the relative position of the vertex on the graph. To construct the CC structure, we use the 2-clique complex of the input graph. We then proceed to build the CCNN for graph classification, denoted by $\mbox{CCNN}_{Graph}$, which is visualized in Figure \@ref(fig:mesh-net)(c). The matrices used for the construction of $\mbox{CCNN}_{Graph}$ are $B_{0,1},~B_{1,2},~B_{0,2}$, their transpose matrices, and the (co)adjacency matrices $A_{0,1},A_{1,1},~coA_{2,1}$. The cochains of $\mbox{CCNN}_{Graph}$ are constructed as follows. For each graph in the dataset, we set the 0-cochain to be the one-hot vector of size 5 provided by the dataset. This one-hot vector stores the relative position of the vertex on the graph. We also construct the 1-cochain and 2-cochain on the 2-clique complex of the graph by considering the coordinate-wise max value of the one-hot vectors attached to the vertices of each cell. The input to $\mbox{CCNN}_{graoh}$ consists of the 0-cochain provided as a part of the dataset as well as the constructed 1 and 2-cochains. The grey node in Figure \@ref(fig:mesh-net)(c) indicates a simple mean pooling operation. We train this network with a learning rate of 0.005 and no data augmentation.

Table \@ref(tab:wrap-tab) reports the results on the *easy* and the *hard* versions of the datasets^[The difficulty in these datasets is controlled by the compactness degree of the graph clusters; clusters in the 'easy' data have more in-between cluster connections, while clusters in the `hard' data are more isolated [@bianchi2020mincutpool].], and compares them to six state-of-the-art GNNs. As shown in Table \@ref(tab:wrap-tab), CCNNs outperform all six GNNs on the hard dataset, and five of the GNNs on the easy dataset. The proposed CCNN outperforms MinCutPool on the hard dataset, while it attains comparable performance to MinCutPool on the easy dataset.

```{r wrap-tab, echo=FALSE}
dsets <- c('Easy', 'Hard')
graclus <- c('97.81', '69.08')
ndp <- c('97.93', '72.67')
diffpool <- c('98.64', '69.98')
topk <- c('82.47', '42.80')
sagpool <- c('84.23', '37.71')
mincutpool <- c('99.02', '73.80')
ccnn <- c('98.90', '75.59')
domains <- data.frame(
  dsets, graclus, ndp, diffpool, topk, sagpool, mincutpool, ccnn
)
colnames(domains) <- c(
  'Dataset',
  'Graclus',
  'NDP',
  'DiffPool',
  'Top-K',
  'SAGPool',
  'MinCutPool',
  'CCNN'
)
knitr::kable(domains, align=c('l', 'c', 'c', 'c', 'c'), booktabs=TRUE, caption="Predictive accuracy on the test set of [@bianchi2020mincutpool] related to graph classification. All results are reported using the $\\mbox{CCNN}_{Graph}$ architecture.")
```

**Architecture of  $\mbox{CCNN}_{Graph}$**. In the $\mbox{CCNN}_{Graph}$ displayed in Figure \@ref(fig:mesh-net)(c) we choose a CCNN pooling architecture as given in Definition \@ref(def:general-pooling-hoan) that pushes signals from vertices, edges and faces, and aggregate their information towards the higher-order cells before making making the final prediction. For the dataset of [@bianchi2020mincutpool], we experiment with two architectures; the first one is identical to the $\mbox{CCNN}_{SHREC}$ shown in Figure \@ref(fig:mesh-net)(b), and the second one is the $\mbox{CCNN}_{Graph}$ shown in Figure \@ref(fig:mesh-net)(c). We report the results for $\mbox{CCNN}_{Graph}$, as it provides superior performance. Note that when this neural network is conducted on an underlying simplicial complex, the neighborhood matrices $B_{0,1}$ and $B_{1,3}$ are typically not considered, hence the CC-structure equipped with these additional incidence matrices improves the generalization performance of the $\mbox{CCNN}_{Graph}$.

## Pooling with mapper on graphs and data classification

We perform experiments to measure the effectiveness of the MOG pooling strategy discussed in Section \@ref(mapper-and-the-cc-pooling-operation). Recall that the MOG algorithm requires two pieces of input: the 1-skeleton of a CC $\mathcal{X}$, and a scalar function on the vertices of $\mathcal{X}$. Our choice for the input scalar function is the average geodesic distance (AGD) [@KimLipmanChen2010], which is suitable for shape detection as it is invariant to reflection and rotation. For two entities $u$ and $v$ on a graph, the geodesic distance between $u$ and $v$, denoted by $d(v,u)$, is computed using Dijkstra's shortest path algorithm. The AGD is given by the following equation:
\begin{equation}
AGD(v)=\frac{1}{|V|}\sum_{u\in V}d(v,u).
(\#eq:agd)
\end{equation}

From Equation \@ref(eq:agd), it is immediate that the vertices near the center of the graph are likely to have low function values, while points on the periphery are likely to have high values. This observation has been utilized to study graph symmetry [@KimLipmanChen2010], and it provides a justification for selecting the AGD for the MOG pooling strategy. Figure \@ref(fig:pooling-examples) presents a few examples of applying the MOG pooling strategy using AGD on the SHREC11 dataset.

```{r pooling-examples, echo=FALSE, fig.align="center", fig.cap="Examples of applying the MOG algorithm on the SHREC11 dataset [@lian2011shape]. In each figure, we show the original mesh graph on the left and the mapper graph on the right. The scalar function chosen for the MOG algorithm is the average geodesic distance (AGD). We observe that the pooled mapper graph has similar overall shape to the original graphs."}
knitr::include_graphics('figures/pooling_examples.png', dpi=NA)
```

In order to demonstrate the effectiveness of our MOG pooling approach, we conduct three experiments on the SHREC11 dataset: mesh classification based on CC-pooling with input vertex and edge features (Section \@ref(mesh-classification-cc-pooling-with-input-vertex-and-edge-features)), mesh classification based on CC-pooling with input vertex features only (Section \@ref(mesh-classification-cc-pooling-with-input-vertex-features-only)), and point cloud classification based on CC-pooling with input vertex features only (Section \@ref(point-cloud-classification-cc-pooling-with-input-vertex-features-only)). The experiments in Sections \@ref(mesh-classification-cc-pooling-with-input-vertex-and-edge-features) and \@ref(mesh-classification-cc-pooling-with-input-vertex-features-only) utilize the mesh structure in the SHREC11 dataset, whereas the experiment in Section \@ref(point-cloud-classification-cc-pooling-with-input-vertex-features-only) utilizes its own point cloud version. In particular, we choose two simple CCNN architectures shown in Figure \@ref(fig:mesh-net)(d), denoted by $\mbox{CCNN}_{MOG1}$ and $\mbox{CCNN}_{MOG2}$, as opposed to the more complicated architecture of $\mbox{CCNN}_{SHREC}$ in Figure \@ref(fig:mesh-net)(b). The main difference between $\mbox{CCNN}_{MOG1}$ and $\mbox{CCNN}_{MOG2}$ is the choice of the input feature vectors as described next.

### Mesh classification: CC-pooling with input vertex and edge features

In this experiment, we consider the vertex feature vector to be the position concatenated with the normal vectors for each vertex in the underlying mesh. For the edge features, we compute the first ten eigenvectors of the 1-Hodge Laplacian [@dodziuk1976finite; @eckmann1944harmonische] and attach a 10-dimensional feature vector to the edges of the underlying mesh. The CC that we consider here is 3-dimensional, as it consists of the triangular mesh (vertices, edges and faces) and of 3-cells. The 3-cells are obtained using the MOG algorithm, and are used for augmenting each mesh. We calculate the 3-cells via the MOG algorithm using the AGD scalar function as input. We conduct this experiment using the CCNN defined via the tensor diagram $\mbox{CCNN}_{MOG1}$ given in Figure \@ref(fig:mesh-net)(d). During training, we augment each mesh with ten additional meshes, with each of these additional meshes being obtained by a random rotation as well as 0.1% noise perturbation to the vertex positions. We train $\mbox{CCNN}_{MOG1}$ for 100 epochs using a learning rate of 0.0002 and the standard cross-entropy loss, and obtain an accuracy of 98.1%. While the accuracy of $\mbox{CCNN}_{MOG1}$ is lower than the one we report for $\mbox{CCNN}_{SHREC}$ (99.17%) in Table \@ref(tab:shrec), we note that $\mbox{CCNN}_{MOG1}$ requires a significantly smaller number of replications for mesh augmentation to achieve a similar accuracy ($\mbox{CCNN}_{MOG1}$ requires 10, whereas $\mbox{CCNN}_{SHREC}$ required 30 replications).

**Architecture of $\mbox{CCNN}_{MOG1}$**. The tensor diagram $\mbox{CCNN}_{MOG1}$ of Figure \@ref(fig:mesh-net)(d) corresponds to a pooling CCNN. In particular, $\mbox{CCNN}_{MOG1}$ pushes forward the signal towards two different higher-order cells: the faces of the mesh as well as the 3-cells obtained from the MOG algorithm.

### Mesh classification: CC-pooling with input vertex features only

In this experiment, we consider the position and the normal vectors of the input vertices. The CC structure that we consider is the underlying graph structure obtained from each mesh; i.e., we only use the vertices and the edges, and ignore the faces. We augment this structure by 2-cells obtained via the MOG algorithm using the AGD scalar function as input. We choose the network architecture to be relatively simpler than $\mbox{CCNN}_{MOG1}$, and report it in Figure \@ref(fig:mesh-net)(d) as $\mbox{CCNN}_{MOG2}$. During training we augment each mesh with 10 additional meshes, with each of these additional meshes being obtained by a random rotation as well as 0.05% noise perturbation to the vertex positions. We train $\mbox{CCNN}_{MOG2}$ for 100 epochs using a learning rate of 0.0003 and the standard cross-entropy loss, and obtain an accuracy of 97.1%.

**Architecture of $\mbox{CCNN}_{MOG2}$ for mesh classification**. The tensor diagram $\mbox{CCNN}_{MOG2}$ of Figure \@ref(fig:mesh-net)(d) corresponds to a pooling CCNN. In particular, $\mbox{CCNN}_{MOG2}$ pushes forward the signal towards a single 2-cell obtained from the MOG algorithm. Observe that the overall architecture of $\mbox{CCNN}_{MOG2}$ is similar in principle to AlexNet [@krizhevsky2017imagenet], where convolutional layers are followed by pooling layers.

### Point cloud classification: CC-pooling with input vertex features only

In this experiment, we consider point cloud classification on the SHREC11 dataset. The setup is similar in principle to the one studied in Section \@ref(mesh-classification-cc-pooling-with-input-vertex-features-only) where we consider only the features supported on the vertices of the point cloud as input. Specifically, for each mesh in the SHREC11 dataset, we sample 1,000 points from the surface of the mesh. Additionally, we estimate the normal vectors of the resulting point clouds using the Point Cloud Utils package [@point-cloud-utils]. To build the CC structure, we first consider the $k$-nearest neighborhood graph obtained from each point cloud using $k=7$. We then augment this graph by 2-cells obtained via the MOG algorithm using the AGD scalar function as input. We train the $\mbox{CCNN}_{MOG2}$ shown in Figure \@ref(fig:mesh-net)(d). During training, we augment each point cloud with 12 additional instances, each one of these instances being obtained by random rotation. We train $\mbox{CCNN}_{MOG2}$ for 100 epochs using a learning rate of 0.0003 and the standard cross-entropy loss, and obtain an accuracy of 95.2% (see Table \@ref(tab:shrec)).

## Ablation studies

In this section, we perform two ablation studies. The first ablation study reveals that pooling strategies in CCNNs have a crucial effect on predictive performance. The second ablation study demonstrates that CCNNs have better predictive capacity than GNNs; the advantage of CCNNs arises from their topological pooling operations and from their ability to learn from topological features.

**Pooling strategies in CCNNs**. To evaluate the impact of the choice of pooling strategy on predictive performance, we experiment with two pooling strategies using the SHREC11 classification dataset. The first pooling strategy is the MOG algorithm described in Section \@ref(pooling-with-mapper-on-graphs-and-data-classification); the results of this pooling strategy based on $\mbox{CCNN}_{MOG2}$ are discussed in Section \@ref(mesh-classification-cc-pooling-with-input-vertex-features-only) (97.1%). The second pooling strategy is briefly described as follows. For each mesh, we consider the 2-dimensional CC obtained by considering each 1-hop neighborhood to be the 1-cells in the CC and each 2-hop neighborhood to be the 2-cells in the CC. We train $\mbox{CCNN}_{MOG2}$, and obtain an accuracy of 89.2%, which is lower than 97.1%. These experiments suggest that the choice of pooling strategy has a crucial effect on predictive performance.

**Comparing CCNNs to GNNs in terms of predictive performance**. Observe that $\mbox{CCNN}_{SHREC}$ has topological features of dimension one and two as inputs. On the other hand, $\mbox{CCNN}_{MOG2}$ has only vertex features as input, but it learns the higher-order cell latent features by using the push-forward operation that pushes the signal from 0-cells to the 2-cells obtained from the MOG algorithm. In both cases, using a higher-order structure is essential for improving predictive performance, even though two different strategies towards exploiting the higher-order structures are utilized. To support our claim, we run an experiment in which we replace the pooling layer in $\mbox{CCNN}_{MOG2}$ by the cochain operator induced by $A_{0,1}$, effectively rendering the neural network as a GNN. In this setting, using the same setup as in experiment \@ref(mesh-classification-cc-pooling-with-input-vertex-features-only), we obtain an accuracy of 84.56%. This experiment reveals the performance advantages of employing higher-order structures, either by utilizing the input topological features supported on higher-order cells or via pooling strategies that augment higher-order cells.
